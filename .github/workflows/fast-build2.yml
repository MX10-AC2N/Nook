name: üöÄ Fast Build & Push 2 (Manual)

on:
  workflow_dispatch:  # D√©clenchement manuel uniquement
  push:
    branches: [develop, main]
    paths:
      - 'backend/**'
      - 'frontend/**'
      - 'Dockerfile'
      - '.github/workflows/fast-build.yml'
      - 'Cargo.lock'
      - 'frontend/package-lock.json'

env:
  CARGO_TERM_COLOR: always
  RUST_LOG: warn

jobs:
  setup:
    name: üîß Setup
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: stable
          components: rustfmt, clippy

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Cache Cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-

  backend:
    name: üèóÔ∏è Backend
    runs-on: ubuntu-latest
    needs: setup

    defaults:
      run:
        working-directory: ./backend

    services:
      sqlite:
        image: alpine:latest
        ports: []
        options: >-
          --entrypoint /bin/sh
          --name sqlite-service
          alpine -c "apk add sqlite && tail -f /dev/null"

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: stable
          components: rustfmt, clippy

      - name: Cache Cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-${{ hashFiles('backend/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-

      - name: G√©n√©rer Cargo.lock
        run: |
          if [ ! -f "Cargo.lock" ]; then
            cargo generate-lockfile
          fi

      - name: V√©rifier d√©pendances
        run: cargo check --all-targets

      - name: Formattage code
        run: cargo fmt --all -- --check

      - name: Analyse statique
        run: cargo clippy -- -D warnings

      - name: Pr√©parer environnement SQLx
        run: |
          mkdir -p /tmp/nook-data
          mkdir -p migrations
          
          # Copier les migrations existantes
          if [ -d "../../backend/migrations" ]; then
            cp -r ../../backend/migrations/* migrations/
          fi
          
          # Cr√©er une base de donn√©es temporaire
          sqlite3 /tmp/nook-data/nook.db "VACUUM;"
          echo "DATABASE_URL=sqlite:/tmp/nook-data/nook.db" > .env

      - name: Installer sqlx-cli
        run: |
          cargo install sqlx-cli --version 0.8.6 --no-default-features --features sqlite --locked

      - name: Appliquer toutes les migrations
        env:
          DATABASE_URL: "sqlite:/tmp/nook-data/nook.db"
        run: |
          echo "üîÑ Application des migrations SQL..."
          
          # Liste toutes les migrations
          if [ -d "migrations" ] && [ "$(ls -A migrations 2>/dev/null)" ]; then
            echo "üìÅ Migrations trouv√©es:"
            ls -la migrations/
            
            # Appliquer chaque migration dans l'ordre
            for migration in migrations/*.sql; do
              if [ -f "$migration" ]; then
                echo "üîß Application de $(basename $migration)..."
                sqlx migrate run --source . --database-url "$DATABASE_URL"
              fi
            done
            
            echo "‚úÖ Toutes les migrations appliqu√©es"
          else
            echo "‚ö†Ô∏è Aucune migration trouv√©e, cr√©ation des tables de base..."
            sqlite3 /tmp/nook-data/nook.db "
              CREATE TABLE IF NOT EXISTS users (
                id TEXT PRIMARY KEY,
                name TEXT NOT NULL,
                username TEXT NOT NULL UNIQUE,
                password_hash TEXT NOT NULL,
                role TEXT NOT NULL DEFAULT 'member',
                approved BOOLEAN NOT NULL DEFAULT 0,
                created_at INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
                public_key TEXT,
                private_key_encrypted TEXT
              );
              
              CREATE TABLE IF NOT EXISTS sessions (
                token TEXT PRIMARY KEY,
                user_id TEXT NOT NULL,
                expires_at INTEGER NOT NULL,
                FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE
              );
              
              CREATE TABLE IF NOT EXISTS conversations (
                id TEXT PRIMARY KEY,
                name TEXT,
                is_group BOOLEAN NOT NULL DEFAULT 0,
                created_at INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
                last_message_at INTEGER,
                last_message_preview TEXT,
                unread_count INTEGER DEFAULT 0
              );
              
              CREATE TABLE IF NOT EXISTS conversation_members (
                conversation_id TEXT NOT NULL,
                user_id TEXT NOT NULL,
                joined_at INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
                FOREIGN KEY(conversation_id) REFERENCES conversations(id) ON DELETE CASCADE,
                FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE,
                PRIMARY KEY(conversation_id, user_id)
              );
              
              CREATE TABLE IF NOT EXISTS messages (
                id TEXT PRIMARY KEY,
                conversation_id TEXT NOT NULL,
                sender_id TEXT NOT NULL,
                content TEXT,
                encrypted_keys TEXT,
                nonce TEXT,
                media_type TEXT,
                media_url TEXT,
                duration INTEGER,
                timestamp INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
                FOREIGN KEY(conversation_id) REFERENCES conversations(id) ON DELETE CASCADE,
                FOREIGN KEY(sender_id) REFERENCES users(id) ON DELETE CASCADE
              );
              
              CREATE TABLE IF NOT EXISTS message_reactions (
                message_id TEXT NOT NULL,
                user_id TEXT NOT NULL,
                emoji TEXT NOT NULL,
                created_at INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
                FOREIGN KEY(message_id) REFERENCES messages(id) ON DELETE CASCADE,
                FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE,
                PRIMARY KEY(message_id, user_id, emoji)
              );
            "
            echo "‚úÖ Tables de base cr√©√©es"
          fi

      - name: G√©n√©rer cache SQLx
        env:
          DATABASE_URL: "sqlite:/tmp/nook-data/nook.db"
          SQLX_OFFLINE: "true"
        run: |
          echo "üîÑ G√©n√©ration du cache SQLx..."
          
          # V√©rifier que les tables existent
          TABLES=$(sqlite3 /tmp/nook-data/nook.db ".tables")
          echo "üìã Tables disponibles: $TABLES"
          
          # G√©n√©rer le cache
          cargo sqlx prepare -- --all-targets --lib
          
          # V√©rifier que le cache a √©t√© g√©n√©r√©
          if [ -d ".sqlx" ]; then
            echo "‚úÖ Cache SQLx g√©n√©r√© avec succ√®s"
            ls -la .sqlx/
          else
            echo "‚ùå √âchec de la g√©n√©ration du cache SQLx"
            exit 1
          fi

      - name: Build Release
        env:
          SQLX_OFFLINE: true
        run: cargo build --release --locked

      - name: V√©rifier binaire
        run: |
          BIN_PATH="target/release/nook-backend"
          if [ ! -f "$BIN_PATH" ]; then
            echo "‚ùå Binaire manquant: $BIN_PATH"
            exit 1
          fi
          
          # V√©rifier les permissions
          chmod +x "$BIN_PATH"
          
          # V√©rifier la taille raisonnable
          SIZE=$(stat -c%s "$BIN_PATH")
          if [ "$SIZE" -lt 1000000 ]; then
            echo "‚ö†Ô∏è Binaire tr√®s petit ($SIZE octets), v√©rification n√©cessaire"
          fi
          
          echo "‚úÖ Binaire g√©n√©r√©: $BIN_PATH ($SIZE octets)"

      - name: Upload backend artifact
        uses: actions/upload-artifact@v4
        with:
          name: nook-backend-${{ github.sha }}
          path: backend/target/release/nook-backend
          retention-days: 1

  frontend:
    name: üé® Frontend
    runs-on: ubuntu-latest
    needs: setup

    defaults:
      run:
        working-directory: ./frontend

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: V√©rifier existence frontend/
        run: |
          if [ ! -d "." ]; then
            echo "‚ùå Dossier frontend absent"
            exit 1
          fi
          echo "‚úÖ Dossier frontend trouv√©"

      - name: Installer d√©pendances
        run: npm ci --no-audit --no-fund

      - name: V√©rifier d√©pendances critiques
        run: |
          REQUIRED_DEPS=(
            "svelte"
            "sveltekit"
            "libsodium-wrappers"
            "uuid"
          )
          
          for dep in "${REQUIRED_DEPS[@]}"; do
            if ! npm list "$dep" --depth=0 --silent; then
              echo "‚ö†Ô∏è D√©pendance manquante: $dep"
            else
              echo "‚úÖ $dep install√©"
            fi
          done

      - name: Lint
        run: npm run lint

      - name: Build
        run: npm run build

      - name: V√©rifier build/
        run: |
          BUILD_DIR="build"
          
          if [ ! -d "$BUILD_DIR" ]; then
            echo "‚ùå Dossier $BUILD_DIR absent"
            exit 1
          fi
          
          # V√©rifier les fichiers essentiels
          REQUIRED_FILES=(
            "index.html"
            "_app/manifest.json"
            "_app/version.json"
          )
          
          for file in "${REQUIRED_FILES[@]}"; do
            if [ ! -f "$BUILD_DIR/$file" ]; then
              echo "‚ùå Fichier manquant: $BUILD_DIR/$file"
              exit 1
            fi
            echo "‚úÖ $file pr√©sent"
          done
          
          echo "‚úÖ Dossier $BUILD_DIR OK"

      - name: Upload frontend artifact
        uses: actions/upload-artifact@v4
        with:
          name: nook-frontend-${{ github.sha }}
          path: frontend/build
          retention-days: 1

  docker:
    name: üê≥ Docker Build & Push
    runs-on: ubuntu-latest
    needs: [backend, frontend]
    permissions:
      contents: read
      packages: write
      id-token: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download backend artifact
        uses: actions/download-artifact@v4
        with:
          name: nook-backend-${{ github.sha }}
          path: backend-artifact

      - name: Download frontend artifact
        uses: actions/download-artifact@v4
        with:
          name: nook-frontend-${{ github.sha }}
          path: frontend-artifact

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build & Push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: |
            ghcr.io/mx10-ac2n/nook:${{ github.sha }}
            ghcr.io/mx10-ac2n/nook:latest
          build-args: |
            BACKEND_PATH=backend-artifact/nook-backend
            FRONTEND_PATH=frontend-artifact
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64,linux/arm64

      - name: Cleanup artifacts
        if: always()
        run: |
          rm -rf backend-artifact || true
          rm -rf frontend-artifact || true
